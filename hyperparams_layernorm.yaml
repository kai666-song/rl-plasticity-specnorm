# =============================================================================
# LayerNorm Experiment Configuration (LayerNorm 实验配置)
# =============================================================================
# Usage: python train.py -p hyperparams_layernorm.yaml -o results/ablation_studies/layernorm_experiment -n layernorm
# =============================================================================

experiment:
  algo: ppo
  save_freq: 200
  
  conditions:
    layernorm:
      model.layernorm: true
  
  name: null
  num_sessions: 1

environment:
  name: procgen
  task: coinrun_100
  shift_type: permute
  obs_type: conv64
  env_copies: 8

model:
  enc_type: null
  h_size: 256
  lr: 0.0005
  l2_norm: 0.00
  l2_init: 0.00
  w2_init: 0.00
  redo_weight: 0.00
  redo_freq: 10
  activation: relu
  layernorm: false
  specnorm: false
  adapt_info: ['none', null]

ppo_trainer:
  batch_size: 64
  buffer_size: 1024
  num_passes: 3
  ent_coef: 0.02
  gamma: 0.99
  lambda: 0.95
  clip_param: 0.2
  num_epochs: 3000
  shift_points: [1000, 2000]
  test_episodes: 30
  test_interval: 50
