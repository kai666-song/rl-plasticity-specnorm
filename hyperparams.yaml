# =============================================================================
# Hyperparameters Configuration (超参数配置)
# =============================================================================
# 主配置文件，包含所有核心实验的配置
#
# 核心实验配置：
# - baseline: 基准方法（ReLU，无特殊处理）
# - layernorm: LayerNorm 归一化
# - redo-reset: ReDo 周期性重置休眠神经元
# - specnorm: 谱归一化（我们的方法）
#
# Usage:
#   python train.py -p hyperparams.yaml -c baseline -n baseline_exp
#   python train.py -p hyperparams.yaml -c specnorm -n specnorm_exp
# =============================================================================

experiment:
  algo: ppo
  save_freq: 1000
  
  # 核心实验配置（保留最终报告中使用的配置）
  conditions:
    # 基准方法：标准 ReLU，无特殊处理
    baseline:
      model.adapt_info: ['none', null]
      model.specnorm: false
      model.layernorm: false
      model.redo_weight: 0.00
    
    # LayerNorm：工业界常用的归一化方法
    layernorm:
      model.layernorm: true
      model.specnorm: false
      model.redo_weight: 0.00
    
    # ReDo Reset：周期性重置休眠神经元
    redo-reset:
      model.redo_weight: 0.025
      model.redo_freq: 10
      model.specnorm: false
      model.layernorm: false
    
    # Spectral Norm：谱归一化（我们的方法）
    specnorm:
      model.specnorm: true
      model.layernorm: false
      model.redo_weight: 0.00
    
    # 消融实验：激活函数
    leaky-relu:
      model.activation: leaky_relu
      model.specnorm: false
    
    mish:
      model.activation: mish
      model.specnorm: false
    
    # 消融实验：RMSNorm
    rmsnorm:
      model.rmsnorm: true
      model.specnorm: false
  
  name: null
  num_sessions: 1

environment:
  name: procgen
  task: coinrun_100
  shift_type: permute
  obs_type: conv64
  env_copies: 11

model:
  enc_type: null
  h_size: 256
  lr: 0.0005
  l2_norm: 0.00
  l2_init: 0.00
  w2_init: 0.00
  redo_weight: 0.00
  redo_freq: 10
  activation: relu
  layernorm: false
  rmsnorm: false
  specnorm: false
  adapt_info: ['none', null]

ppo_trainer:
  batch_size: 64
  buffer_size: 1024
  num_passes: 3
  ent_coef: 0.02
  gamma: 0.99
  lambda: 0.95
  clip_param: 0.2
  num_epochs: 50000
  shift_points: [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000]
  test_episodes: 50
  test_interval: 100
